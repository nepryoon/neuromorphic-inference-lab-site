<!doctype html>
<html lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Visual Inspector | Neuromorphic Inference Lab</title>
  <meta name="description" content="Visual Inspector: upload an image, inspect basic properties locally, and optionally call an API endpoint." />
  <link rel="icon" href="/favicon.svg" />
  <link rel="stylesheet" href="/style.css" />

  <style>
    /* Visual Inspector-specific styles */
    .hero{
      margin-top:22px;padding:22px;border-radius:var(--radius);border:1px solid var(--border);
      background:linear-gradient(135deg, rgba(255,255,255,.06), rgba(255,255,255,.03));
      box-shadow:var(--shadow);position:relative;overflow:hidden;
    }
    .hero:before{
      content:"";position:absolute;inset:-2px;
      background:
        radial-gradient(420px 260px at 10% 20%, rgba(100,255,218,.20), transparent 55%),
        radial-gradient(420px 260px at 90% 40%, rgba(124,92,255,.18), transparent 60%);
      pointer-events:none;filter:blur(1px);
    }
    .hero>*{position:relative;}
    h1{margin:0 0 8px;font-size:clamp(28px,4vw,42px);line-height:1.12;letter-spacing:.2px;}
    .subtitle{margin:0;color:var(--muted);max-width:92ch;}

    .rowWrap{margin-top:14px;display:flex;gap:10px;flex-wrap:wrap;align-items:center;}

    .kbd{
      font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;
      font-size:12px;padding:2px 8px;border:1px solid rgba(255,255,255,.14);
      background:rgba(0,0,0,.25);border-radius:999px;color:rgba(255,255,255,.78);
    }

    .badge.ok{border-color:rgba(67,251,164,.35);background:rgba(67,251,164,.10);color:rgba(255,255,255,.90);}
    .badge.bad{border-color:rgba(255,77,109,.35);background:rgba(255,77,109,.10);color:rgba(255,255,255,.90);}
    .badge.warn{border-color:rgba(255,206,87,.30);background:rgba(255,206,87,.10);color:rgba(255,255,255,.90);}

    .grid{margin-top:16px;display:grid;gap:12px;grid-template-columns:1.2fr .8fr;align-items:start;}
    @media (max-width:980px){.grid{grid-template-columns:1fr;}}

    .muted{color:var(--muted);}
    .small{font-size:14px;}
    .mono{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;}
    .divider{height:1px;background:rgba(255,255,255,.08);margin:14px 0;}

    .toggle{
      display:inline-flex;gap:8px;align-items:center;border:1px solid rgba(255,255,255,.12);
      background:rgba(0,0,0,.18);padding:6px;border-radius:999px;
    }
    .toggle button{
      border:0;background:transparent;color:rgba(255,255,255,.75);
      padding:8px 10px;border-radius:999px;cursor:pointer;font-weight:700;font-size:12px;
    }
    .toggle button.active{
      color:rgba(255,255,255,.92);
      background:linear-gradient(135deg, rgba(100,255,218,.16), rgba(124,92,255,.12));
      border:1px solid rgba(100,255,218,.30);
    }

    .drop{
      border-radius:14px;border:1px dashed rgba(255,255,255,.18);
      background:rgba(0,0,0,.16);padding:14px;
      display:flex;gap:12px;align-items:center;justify-content:space-between;flex-wrap:wrap;
    }
    input[type="file"]{color:rgba(255,255,255,.78);}

    .preview{
      border-radius:14px;border:1px solid rgba(255,255,255,.10);
      background:rgba(0,0,0,.18);overflow:hidden;
      display:flex;align-items:center;justify-content:center;min-height:240px;
    }
    .preview img{max-width:100%;max-height:360px;display:block;}

    footer{margin-top:24px;color:rgba(255,255,255,.55);font-size:13px;}
  </style>
</head>

<body>
<header class="nav">
  <div class="inner">
    <a class="brand" href="/" aria-label="Neuromorphic Inference Lab home">
      <img src="/logo.svg" alt="Neuromorphic Inference Lab" />
      <span>Neuromorphic Inference Lab</span>
    </a>

    <nav class="navlinks" aria-label="Primary navigation">
      <a data-nav href="/">Home</a>
      <a data-nav href="/demos/" data-active="true">Projects</a>
      <a data-nav href="/about/">About Me</a>
    </nav>
  </div>
</header>

<main class="container">
  <section class="hero">
    <h1>Visual Inspector</h1>
    <p class="subtitle">
      An image analysis tool that runs locally in the browser or connects to a cloud API.
    </p>

    <div class="rowWrap">
      <a class="btn" href="https://github.com/nepryoon/nil-visual-inspector" target="_blank" rel="noopener noreferrer">GitHub</a>

      <span class="toggle" role="group" aria-label="Mode selector">
        <button id="modeLocal" class="active" type="button">Local</button>
        <button id="modeApi" type="button">API</button>
      </span>
      <span class="badge warn" id="bMode">mode: local</span>
      <span class="badge" id="bStatus">status: idle</span>
    </div>
  </section>

  <section class="card" style="margin-top:22px;">
    <h2>Overview</h2>
    <p>
      Visual Inspector analyzes images to extract basic properties like dimensions, color distribution, and brightness. It operates in two modes: local processing that runs entirely in your browser, and API mode that sends images to a remote endpoint for analysis.
    </p>
    <p>
      This tool addresses the need for quick image analysis without installing software or sharing data with third parties. Local mode provides instant feedback on image characteristics. API mode demonstrates integration with deployed inference services.
    </p>
    <p>
      The project demonstrates frontend image processing, canvas manipulation, API integration, and progressive enhancement principles. It shows how to build responsive interfaces that work offline while offering extended functionality when connected.
    </p>

    <div class="divider"></div>

    <details style="margin-top:14px;">
      <summary style="cursor:pointer;font-weight:700;font-size:16px;padding:8px 0;">Technical Details</summary>
      
      <div style="margin-top:14px;">
        <h3>Purpose and Scope</h3>
        <p class="muted small">
          Visual Inspector provides a minimal reference implementation for client-side image analysis and optional server communication. It validates the approach of processing data locally first, then optionally enhancing with remote capabilities. The scope is deliberately constrained to basic statistical analysis to keep the implementation transparent and maintainable.
        </p>

        <h3>Architecture</h3>
        <p class="muted small">
          The architecture follows a single-page application pattern with no build step. The HTML file contains structure, styling, and behavior in one document for portability. Local processing uses the Canvas API to extract pixel data and compute statistics. API mode uses FormData and fetch to send images to a REST endpoint.
        </p>
        <p class="muted small">
          The design separates concerns through function boundaries: UI state management (mode switching, status badges), image loading (file input, object URLs), local analysis (canvas operations, pixel math), and API communication (fetch with timeout, error handling). This separation allows each component to be tested and modified independently.
        </p>

        <h3>Data Flow</h3>
        <p class="muted small">
          1. User selects image file → 2. Browser creates object URL → 3. Image loads into preview → 4. User triggers analysis → 5a. Local: Canvas extracts pixels, computes RGB averages, calculates brightness → 5b. API: Image converts to blob, uploads via FormData POST → 6. Results display as JSON.
        </p>
        <p class="muted small">
          Local analysis downscales images to 640px maximum dimension before processing to limit memory usage and computation time. The downscaling uses canvas context drawing which applies smoothing by default. RGB values are averaged across all pixels, then brightness is calculated using the standard luminance formula (0.2126R + 0.7152G + 0.0722B).
        </p>

        <h3>Technology Stack</h3>
        <p class="muted small">
          <strong>HTML/CSS/JavaScript:</strong> Chosen for zero-dependency deployment and universal browser compatibility. No framework overhead means faster load times and simpler debugging.
        </p>
        <p class="muted small">
          <strong>Canvas API:</strong> Provides direct pixel access for image analysis. The getImageData method returns RGBA values as a typed array which enables efficient numerical operations. The willReadFrequently context hint optimizes for repeated reads.
        </p>
        <p class="muted small">
          <strong>Fetch API with AbortController:</strong> Modern replacement for XMLHttpRequest that supports promises and request cancellation. The 12-second timeout prevents indefinite hangs if the API is unresponsive.
        </p>
        <p class="muted small">
          <strong>FormData:</strong> Standard multipart/form-data encoding for file uploads. Avoids manual base64 encoding which increases payload size by 33%.
        </p>
        <p class="muted small">
          <strong>CSS Grid and Flexbox:</strong> Responsive layout without media query complexity. Grid handles the two-column structure, flexbox manages inline elements and wrapping.
        </p>

        <h3>Implementation Challenges</h3>
        <p class="muted small">
          <strong>Memory management:</strong> Large images can exhaust browser memory. The solution downscales before analysis and revokes object URLs when clearing to prevent leaks.
        </p>
        <p class="muted small">
          <strong>API reliability:</strong> Network requests can fail or timeout. The implementation wraps fetch with AbortController for timeouts and parses responses defensively to handle both JSON and plain text errors.
        </p>
        <p class="muted small">
          <strong>Color space:</strong> Canvas returns sRGB values but brightness perception is non-linear. Using the ITU-R BT.709 luminance coefficients provides perceptually accurate brightness calculation.
        </p>
        <p class="muted small">
          <strong>Browser compatibility:</strong> Modern APIs like willReadFrequently are optional. The code uses progressive enhancement: core functionality works everywhere, optimizations apply when available.
        </p>

        <h3>Trade-offs</h3>
        <p class="muted small">
          <strong>Single-file architecture:</strong> Simpler deployment but harder to maintain as complexity grows. Acceptable for this scope, would require refactoring at larger scale.
        </p>
        <p class="muted small">
          <strong>Client-side processing:</strong> Faster for simple operations, limited by browser capabilities. Complex computer vision would require server-side processing with specialized libraries.
        </p>
        <p class="muted small">
          <strong>Image downscaling:</strong> Reduces accuracy but enables processing of high-resolution images without crashes. The 640px limit balances detail preservation with performance.
        </p>
      </div>
    </details>
  </section>

  <section class="grid">
    <div class="card">
      <h2>Try it</h2>
      <p class="muted small">
        Local mode calculates simple statistics (dimensions, average brightness, dominant channel). API mode expects
        <span class="mono">POST /vision/predict</span> (optional).
      </p>

      <div class="drop">
        <div class="small" style="color:rgba(255,255,255,.85);font-weight:700;">Choose an image</div>
        <input id="file" type="file" accept="image/*" />
        <button class="btn primary" id="btnRun" type="button">Analyse</button>
        <button class="btn" id="btnClear" type="button">Clear</button>
      </div>

      <div class="divider"></div>

      <div class="preview" id="preview"><div class="muted small">No image loaded</div></div>

      <div class="divider"></div>

      <h2>Output</h2>
      <pre id="out">{}</pre>
    </div>

    <aside class="card">
      <h2>Links</h2>
      <div class="small" style="display:grid;gap:10px;">
        <a class="btn" style="justify-content:space-between;" href="https://github.com/nepryoon/nil-visual-inspector" target="_blank" rel="noopener noreferrer"><span>Repository</span><span class="kbd">GitHub</span></a>
      </div>

      <div class="divider"></div>

      <h2>Notes</h2>
      <p class="muted small" style="margin:0;">
        The local analysis is intentionally lightweight. When API mode is enabled, this page can act as a thin client.
      </p>
    </aside>
  </section>

  <footer>© 2025 Neuromorphic Inference Lab — Visual Inspector</footer>
</main>

<script>
  const API_BASE = "https://api.neuromorphicinference.com";

  const el = {
    file: document.getElementById("file"),
    btnRun: document.getElementById("btnRun"),
    btnClear: document.getElementById("btnClear"),
    preview: document.getElementById("preview"),
    out: document.getElementById("out"),
    bStatus: document.getElementById("bStatus"),
    bMode: document.getElementById("bMode"),
    modeLocal: document.getElementById("modeLocal"),
    modeApi: document.getElementById("modeApi"),
  };

  let mode = "local";
  let imgEl = null;
  let objectUrl = null;

  function setMode(next) {
    mode = next;
    el.modeLocal.classList.toggle("active", mode === "local");
    el.modeApi.classList.toggle("active", mode === "api");
    el.bMode.textContent = `mode: ${mode}`;
    el.bMode.classList.remove("ok","bad","warn");
    el.bMode.classList.add("warn");
  }

  function setBadge(text, state) {
    el.bStatus.textContent = text;
    el.bStatus.classList.remove("ok","bad","warn");
    if (state) el.bStatus.classList.add(state);
  }

  function showPreview(src) {
    el.preview.innerHTML = "";
    imgEl = new Image();
    imgEl.alt = "Uploaded image preview";
    imgEl.src = src;
    el.preview.appendChild(imgEl);
  }

  function clearAll() {
    el.file.value = "";
    el.preview.innerHTML = `<div class="muted small">No image loaded</div>`;
    el.out.textContent = "{}";
    imgEl = null;
    if (objectUrl) { URL.revokeObjectURL(objectUrl); objectUrl = null; }
    setBadge("status: idle", null);
  }

  function localAnalyse(image) {
    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d", { willReadFrequently: true });
    const w = image.naturalWidth;
    const h = image.naturalHeight;

    const maxSide = 640;
    const scale = Math.min(1, maxSide / Math.max(w, h));
    canvas.width = Math.max(1, Math.round(w * scale));
    canvas.height = Math.max(1, Math.round(h * scale));

    ctx.drawImage(image, 0, 0, canvas.width, canvas.height);
    const img = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const data = img.data;

    let r = 0, g = 0, b = 0;
    for (let i = 0; i < data.length; i += 4) {
      r += data[i];
      g += data[i+1];
      b += data[i+2];
    }

    const n = data.length / 4;
    const avgR = r / n;
    const avgG = g / n;
    const avgB = b / n;
    const brightness = (0.2126*avgR + 0.7152*avgG + 0.0722*avgB) / 255;

    let dominant = "red";
    if (avgG >= avgR && avgG >= avgB) dominant = "green";
    if (avgB >= avgR && avgB >= avgG) dominant = "blue";

    const label = brightness > 0.62 ? "bright" : (brightness < 0.35 ? "dark" : "balanced");

    return {
      mode: "local",
      input: { width: w, height: h },
      resized: { width: canvas.width, height: canvas.height },
      stats: {
        avg_rgb: { r: Math.round(avgR), g: Math.round(avgG), b: Math.round(avgB) },
        brightness: Number(brightness.toFixed(3)),
        dominant_channel: dominant
      },
      output: { label }
    };
  }

  async function fetchWithTimeout(url, opts = {}, ms = 12000) {
    const ctrl = new AbortController();
    const t = setTimeout(() => ctrl.abort(), ms);
    try {
      const res = await fetch(url, {
        ...opts,
        signal: ctrl.signal,
        headers: { "Accept":"application/json", ...(opts.headers || {}) }
      });
      clearTimeout(t);
      return res;
    } catch (e) {
      clearTimeout(t);
      throw e;
    }
  }

  async function run() {
    if (!imgEl) {
      setBadge("status: no image", "warn");
      el.out.textContent = JSON.stringify({ error: "Please load an image first." }, null, 2);
      return;
    }

    setBadge("status: running…", "warn");
    el.btnRun.disabled = true;

    try {
      const t0 = performance.now();
      let result;

      if (mode === "local") {
        result = localAnalyse(imgEl);
      } else {
        const blob = await (await fetch(imgEl.src)).blob();
        const form = new FormData();
        form.append("file", blob, "image.png");

        const r = await fetchWithTimeout(`${API_BASE}/vision/predict`, {
          method: "POST",
          body: form
        });

        const text = await r.text();
        const data = (() => { try { return JSON.parse(text); } catch { return { raw: text }; } })();
        if (!r.ok) throw new Error(`API error (HTTP ${r.status}): ${data?.detail || text}`);

        result = { mode: "api", response: data };
      }

      const t1 = performance.now();
      result.latency_ms = Math.round(t1 - t0);

      el.out.textContent = JSON.stringify(result, null, 2);
      setBadge("status: done", "ok");
    } catch (e) {
      el.out.textContent = JSON.stringify({ error: String(e?.message || e) }, null, 2);
      setBadge("status: error", "bad");
    } finally {
      el.btnRun.disabled = false;
    }
  }

  el.modeLocal.addEventListener("click", () => setMode("local"));
  el.modeApi.addEventListener("click", () => setMode("api"));

  el.file.addEventListener("change", () => {
    const f = el.file.files && el.file.files[0];
    if (!f) return;
    if (objectUrl) URL.revokeObjectURL(objectUrl);
    objectUrl = URL.createObjectURL(f);
    showPreview(objectUrl);
    setBadge("status: image loaded", null);
  });

  el.btnRun.addEventListener("click", run);
  el.btnClear.addEventListener("click", clearAll);
</script>
</body>
</html>
