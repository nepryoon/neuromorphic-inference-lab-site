<!doctype html>
<html lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>RAG Knowledge Copilot — Systems</title>
  <meta name="description" content="Retrieval-augmented generation demo: retrieval tracing, evaluation signals, and LLMOps-ready patterns." />
  <link rel="icon" href="/favicon.svg" />
  <link rel="stylesheet" href="/style.css" />
</head>

<body>
  <header class="nav">
    <div class="inner">
      <a class="brand" href="/" aria-label="Neuromorphic Inference Lab home">
        <img src="/logo.svg" alt="Neuromorphic Inference Lab" />
        <span>Neuromorphic Inference Lab</span>
      </a>

      <nav class="navlinks" aria-label="Primary navigation">
        <a data-nav href="/">Signal</a>
        <a data-nav href="/demos/" data-active="true">Systems</a>
        <a data-nav href="/evidence/">Proof Ledger</a>
        <a data-nav href="/about/">Identity</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <section class="hero">
      <p class="kicker">System · RAG / LLMOps</p>
      <h1 class="h1">RAG Knowledge Copilot</h1>
      <p class="sub">
        A lightweight, ATS-readable demonstration of Retrieval-Augmented Generation concepts:
        chunking, retrieval, traceability, and evaluation signals — designed for production-minded ML engineers.
      </p>

      <div class="badges" aria-label="Core capabilities">
        <span class="badge">RAG</span>
        <span class="badge">LLMOps</span>
        <span class="badge">Retrieval Tracing</span>
        <span class="badge">Evaluation Harness</span>
        <span class="badge">Observability-ready</span>
      </div>
    </section>

    <section class="section">
      <div class="grid">
        <article class="card col-6">
          <h3>Ask a question</h3>
          <p>Query the mini knowledge base. The system will retrieve the most relevant chunks and draft an answer grounded in the retrieved text.</p>

          <div class="field">
            <label for="q">Query</label>
            <input id="q" type="text" placeholder="e.g. How does this RAG pipeline reduce hallucinations?" />
            <div class="helper">Tip: try “chunking strategy”, “evaluation”, “vector store”, or “guardrails”.</div>
          </div>

          <div class="field">
            <label for="k">Top-K retrieval</label>
            <select id="k">
              <option value="3">3</option>
              <option value="5" selected>5</option>
              <option value="8">8</option>
            </select>
          </div>

          <div class="actions">
            <button class="btn primary" id="run">Run retrieval</button>
            <button class="btn" id="reset">Reset</button>
            <a class="btn" href="/evidence/rag-copilot/">Proof ledger</a>
          </div>

          <hr class="hr" />

          <h3>Answer draft</h3>
          <p id="answer" style="margin:0;color:rgba(234,240,255,.84);">
            Run a query to generate a grounded draft.
          </p>

          <div class="helper" id="meta" style="margin-top:10px;"></div>
        </article>

        <article class="card col-6">
          <h3>Retrieval trace</h3>
          <p>Top matches with similarity scores. This is the core artefact recruiters look for in RAG work: transparent retrieval + grounding.</p>

          <div id="trace"></div>

          <hr class="hr" />

          <h3>Knowledge base (editable)</h3>
          <p>Add a new document below; it will be chunked and indexed locally in your browser.</p>

          <div class="field">
            <label for="docTitle">Document title</label>
            <input id="docTitle" type="text" placeholder="e.g. RAG Evaluation Notes" />
          </div>

          <div class="field">
            <label for="docBody">Document text</label>
            <textarea id="docBody" placeholder="Paste a short technical note (2–8 paragraphs)."></textarea>
          </div>

          <div class="actions">
            <button class="btn" id="addDoc">Add to knowledge base</button>
            <button class="btn" id="restore">Restore defaults</button>
          </div>

          <div class="helper" style="margin-top:10px;">
            This demo is static by design (safe for a public portfolio). A production variant would call a secured API and store embeddings in a managed vector database.
          </div>
        </article>

        <article class="card col-12">
          <h3>Production architecture snapshot</h3>
          <p style="margin:0;color:rgba(234,240,255,.78);">
            <strong>Ingestion</strong> → chunking + metadata → embeddings → vector index → retrieval + re-ranking → prompt assembly →
            <strong>LLM</strong> → citations + safety filters → monitoring (latency, cost, drift, answer quality).
          </p>
          <div class="badges" style="margin-top:12px;">
            <span class="badge">Chunking</span>
            <span class="badge">Embeddings</span>
            <span class="badge">Vector Store</span>
            <span class="badge">Re-ranking</span>
            <span class="badge">Guardrails</span>
            <span class="badge">Evaluation</span>
          </div>
        </article>
      </div>
    </section>

    <footer class="footer">
      <div>© <span id="year"></span> Neuromorphic Inference Lab</div>
      <div class="prov">
        <span id="build-branch">branch: …</span>
        <span id="build-commit">commit: …</span>
        <span id="build-time">built: …</span>
      </div>
    </footer>
  </main>

  <script>
    document.getElementById("year").textContent = String(new Date().getFullYear());

    // -----------------------------
    // Minimal in-browser RAG demo
    // (TF-IDF-ish vectors + cosine similarity)
    // -----------------------------

    const DEFAULT_DOCS = [
      {
        title: "RAG basics: grounding and hallucination control",
        text:
`Retrieval-Augmented Generation (RAG) reduces hallucinations by grounding the model response in retrieved documents.
Instead of relying purely on parametric memory, the system retrieves relevant context (chunks) from a knowledge base.
A production implementation should expose retrieval traces and citations to make the system auditable.`
      },
      {
        title: "Chunking strategy and metadata",
        text:
`Chunking is a first-class design choice. Overly large chunks dilute relevance; overly small chunks lose coherence.
Effective pipelines store metadata (source, section, timestamp, tags) to support filtering and governance.
For technical screening, you should be able to explain chunk sizing, overlap, and how you evaluate retrieval quality.`
      },
      {
        title: "Embeddings, vector stores, and retrieval",
        text:
`Embeddings convert text into vectors for similarity search. A vector store indexes embeddings and supports top-k retrieval.
Common patterns include hybrid retrieval (BM25 + vectors) and re-ranking to improve precision at small k.
Operational considerations include latency budgets, caching, and cost controls for embedding generation.`
      },
      {
        title: "Evaluation harness for RAG (LLMOps)",
        text:
`RAG quality needs measurable evaluation: retrieval precision/recall, answer faithfulness, citation correctness, and robustness on edge cases.
A good harness includes test sets, golden answers, and failure mode tagging (missing context, wrong context, prompt issues).
In production, you log queries, retrieved chunks, latency, and user feedback to drive iterative improvements.`
      },
      {
        title: "Reliability patterns and guardrails",
        text:
`Reliability patterns include: refusing when retrieval is empty, showing citations, enforcing structured outputs, and applying safety filters.
Guardrails can block prompt injection, redact PII, and require source-based claims.
For enterprise readiness, align with data governance policies and implement monitoring for drift and regressions.`
      },
      {
        title: "Deployment notes: CI/CD and monitoring",
        text:
`A full-stack ML engineer treats RAG as a system: CI/CD for changes to prompts, retrievers, and evaluation sets.
Monitoring should cover latency, error rate, cost per query, retrieval hit rate, and quality metrics over time.
This is the difference between a demo and a production service.`
      }
    ];

    let docs = [];
    let chunks = []; // {docTitle, chunkText, tokens, tf}
    let idf = new Map(); // token -> idf
    let vocab = new Set();

    const stop = new Set(["the","a","an","and","or","to","of","in","on","for","with","is","are","as","by","be","this","that","it","at","from"]);

    function normalise(s){
      return s
        .toLowerCase()
        .replace(/[^a-z0-9\s-]/g, " ")
        .replace(/\s+/g, " ")
        .trim();
    }

    function tokenize(s){
      const t = normalise(s).split(" ").filter(x => x && x.length > 2 && !stop.has(x));
      return t;
    }

    function chunkText(text, maxTokens=70, overlap=12){
      const toks = tokenize(text);
      const out = [];
      let i = 0;
      while(i < toks.length){
        const slice = toks.slice(i, i + maxTokens);
        out.push(slice.join(" "));
        i += (maxTokens - overlap);
      }
      return out.length ? out : [normalise(text)];
    }

    function rebuildIndex(){
      chunks = [];
      vocab = new Set();

      // build chunks + TF
      for(const d of docs){
        const parts = chunkText(d.text, 80, 14);
        for(const p of parts){
          const toks = tokenize(p);
          const tf = new Map();
          for(const tok of toks){
            vocab.add(tok);
            tf.set(tok, (tf.get(tok) || 0) + 1);
          }
          chunks.push({ docTitle: d.title, chunkText: p, tokens: toks, tf });
        }
      }

      // IDF
      idf = new Map();
      const N = chunks.length || 1;
      for(const tok of vocab){
        let df = 0;
        for(const c of chunks){
          if(c.tf.has(tok)) df += 1;
        }
        const val = Math.log((N + 1) / (df + 1)) + 1; // smoothed
        idf.set(tok, val);
      }
    }

    function vectorise(tokens){
      const v = new Map();
      for(const t of tokens){
        const w = idf.get(t) || 1;
        v.set(t, (v.get(t) || 0) + w);
      }
      return v;
    }

    function cosine(a,b){
      let dot = 0;
      let na = 0;
      let nb = 0;

      for(const [k,va] of a.entries()){
        na += va * va;
        const vb = b.get(k);
        if(vb) dot += va * vb;
      }
      for(const vb of b.values()){
        nb += vb * vb;
      }
      na = Math.sqrt(na) || 1e-9;
      nb = Math.sqrt(nb) || 1e-9;
      return dot / (na * nb);
    }

    function topK(query, k){
      const qtoks = tokenize(query);
      const qv = vectorise(qtoks);

      const scored = chunks.map((c) => {
        const cv = vectorise(c.tokens);
        const s = cosine(qv, cv);
        return { ...c, score: s };
      });

      scored.sort((x,y) => y.score - x.score);
      return scored.slice(0, k);
    }

    function escapeHtml(s){
      return s.replace(/[&<>"]/g, (ch) => ({ "&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;" }[ch]));
    }

    function renderTrace(items){
      const el = document.getElementById("trace");
      if(!items.length){
        el.innerHTML = `<p style="margin:0;color:rgba(234,240,255,.75);">No matches. Try a more specific query.</p>`;
        return;
      }

      el.innerHTML = items.map((it, idx) => `
        <div style="padding:12px;border:1px solid rgba(255,255,255,.10);border-radius:16px;background:rgba(255,255,255,.04);margin:0 0 10px;">
          <div style="display:flex;justify-content:space-between;gap:12px;align-items:flex-start;">
            <div style="font-weight:650;">${idx+1}. ${escapeHtml(it.docTitle)}</div>
            <div style="color:rgba(234,240,255,.70);font-size:12px;">score: ${it.score.toFixed(3)}</div>
          </div>
          <div style="margin-top:8px;color:rgba(234,240,255,.78);font-size:13px;">
            ${escapeHtml(it.chunkText)}
          </div>
        </div>
      `).join("");
    }

    function draftAnswer(query, items){
      if(!items.length){
        return "I can’t find relevant context in the current knowledge base. Add a document or refine the query.";
      }

      const best = items[0];
      return (
`Grounded draft (from retrieved context): ${best.chunkText}

Operational note: in a production RAG system, this draft would be generated by an LLM with strict citation rules, prompt-injection defences, and monitoring for drift and regressions.`
      );
    }

    // UI wiring
    function init(){
      docs = JSON.parse(JSON.stringify(DEFAULT_DOCS));
      rebuildIndex();

      document.getElementById("run").addEventListener("click", () => {
        const q = document.getElementById("q").value.trim();
        const k = parseInt(document.getElementById("k").value, 10);

        const t0 = performance.now();
        const items = q ? topK(q, k) : [];
        const t1 = performance.now();

        renderTrace(items);

        const answer = q ? draftAnswer(q, items) : "Enter a query to generate a grounded draft.";
        document.getElementById("answer").textContent = answer;

        const meta = q
          ? `Latency: ${(t1 - t0).toFixed(1)} ms · Chunks indexed: ${chunks.length} · Keywords: CI/CD for ML, Feature Stores, Automated Retraining, Inference Scaling, RAG, LLMOps`
          : "";
        document.getElementById("meta").textContent = meta;
      });

      document.getElementById("reset").addEventListener("click", () => {
        document.getElementById("q").value = "";
        document.getElementById("answer").textContent = "Run a query to generate a grounded draft.";
        document.getElementById("trace").innerHTML = "";
        document.getElementById("meta").textContent = "";
      });

      document.getElementById("addDoc").addEventListener("click", () => {
        const title = document.getElementById("docTitle").value.trim() || "Untitled note";
        const body = document.getElementById("docBody").value.trim();
        if(!body){
          alert("Please paste some document text before adding.");
          return;
        }
        docs.unshift({ title, text: body });
        rebuildIndex();
        document.getElementById("docTitle").value = "";
        document.getElementById("docBody").value = "";
        alert(`Added: "${title}" (index rebuilt).`);
      });

      document.getElementById("restore").addEventListener("click", () => {
        docs = JSON.parse(JSON.stringify(DEFAULT_DOCS));
        rebuildIndex();
        alert("Default knowledge base restored.");
      });
    }

    init();
  </script>
  <script src="/build-info.js"></script>
</body>
</html>
