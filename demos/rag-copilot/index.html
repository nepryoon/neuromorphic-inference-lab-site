<!doctype html>
<html lang="en-GB">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>RAG Copilot â€” PDF Knowledge Demo â€” Neuromorphic Inference Lab</title>
  <meta name="description" content="RAG Knowledge Copilot: PDF upload, vector indexing, contextual chat with citations, and automated benchmark evaluation." />
  <link rel="icon" href="/favicon.svg" />
  <link rel="stylesheet" href="/style.css" />

  <style>
    /* Upload Zone */
    .upload-zone {
      border: 2px dashed #333;
      border-radius: 8px;
      padding: 2rem;
      text-align: center;
      cursor: pointer;
      transition: border-color .2s;
      margin: 1rem 0;
    }
    .upload-zone:hover {
      border-color: #00ff88;
    }
    .upload-zone.drag-over {
      border-color: #4fc3f7;
      background: rgba(79, 195, 247, 0.05);
    }
    
    /* Progress Bar */
    .progress-bar-wrapper {
      background: #1a1a1a;
      border-radius: 4px;
      height: 6px;
      overflow: hidden;
      margin: .8rem 0;
    }
    .progress-bar {
      height: 100%;
      background: linear-gradient(90deg, #00ff88, #4fc3f7);
      width: 0%;
      transition: width .4s ease;
    }
    
    /* Ingest Result */
    .ingest-result {
      padding: 1rem;
      border-radius: 6px;
      margin-top: 1rem;
      font-family: monospace;
      font-size: .9rem;
    }
    .ingest-result.success {
      background: #0a1f0f;
      border: 1px solid #00ff88;
      color: #00ff88;
    }
    .ingest-result.error {
      background: #1f0a0a;
      border: 1px solid #ff4444;
      color: #ff6666;
    }
    
    /* Chat Window */
    .chat-window {
      background: #0d0d0d;
      border: 1px solid #222;
      border-radius: 8px;
      padding: 1rem;
      height: 350px;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: .8rem;
      margin-bottom: 1rem;
    }
    .chat-message {
      padding: .7rem 1rem;
      border-radius: 6px;
      max-width: 85%;
      font-size: .9rem;
      line-height: 1.6;
    }
    .chat-message.user {
      background: #1a2a1a;
      border: 1px solid #2a4a2a;
      align-self: flex-end;
      color: #ccc;
    }
    .chat-message.assistant {
      background: #111;
      border: 1px solid #333;
      align-self: flex-start;
      color: #eee;
    }
    .chat-message.system {
      background: #0e1520;
      border: 1px solid #1e3a5a;
      align-self: center;
      color: #4fc3f7;
      font-size: .8rem;
    }
    .chat-message.error {
      background: #1f0a0a;
      border: 1px solid #ff4444;
      color: #ff6666;
    }
    
    /* Citations Block */
    .citations-block {
      margin-top: .8rem;
      padding-top: .8rem;
      border-top: 1px solid #2a2a2a;
      font-size: .8rem;
    }
    .citation {
      color: #888;
      margin: .3rem 0;
      padding: .4rem;
      background: #0a0a0a;
      border-radius: 4px;
    }
    .citation-toggle {
      cursor: pointer;
      color: #4fc3f7;
      text-decoration: underline;
      font-size: .75rem;
      margin-top: .5rem;
      display: inline-block;
    }
    
    /* Chat Input */
    .chat-input-row {
      display: flex;
      gap: .5rem;
    }
    .chat-input-row input {
      flex: 1;
      background: #111;
      border: 1px solid #333;
      border-radius: 6px;
      padding: .7rem 1rem;
      color: #eee;
      font-family: monospace;
    }
    .chat-input-row input:focus {
      outline: none;
      border-color: #00ff88;
    }
    
    /* Metrics Table */
    .metrics-table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 1.5rem;
      font-size: .85rem;
    }
    .metrics-table th,
    .metrics-table td {
      padding: .7rem 1rem;
      border: 1px solid #222;
      text-align: left;
    }
    .metrics-table th {
      background: #111;
      color: #4fc3f7;
    }
    .score-cell {
      font-family: monospace;
      color: #00ff88;
      font-weight: bold;
    }
    
    /* Chart */
    #metricsChart {
      background: #0d0d0d;
      border: 1px solid #222;
      border-radius: 8px;
      display: block;
      margin: 1.5rem auto;
      max-width: 100%;
    }
    
    /* Architecture Diagram */
    .architecture-diagram pre {
      background: #0a0a0a;
      border: 1px solid #222;
      border-radius: 6px;
      padding: 1.2rem;
      overflow-x: auto;
      font-size: .78rem;
      color: #4fc3f7;
      line-height: 1.5;
    }
    
    /* Spinner */
    .spinner {
      display: inline-block;
      width: 16px;
      height: 16px;
      border: 2px solid #333;
      border-top-color: #00ff88;
      border-radius: 50%;
      animation: spin .7s linear infinite;
      margin-right: .5rem;
    }
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    
    /* Status Badge */
    .status-badge {
      display: inline-block;
      padding: .4rem .8rem;
      border-radius: 999px;
      font-size: .75rem;
      font-weight: 600;
      margin-left: .5rem;
    }
    .status-badge.online {
      background: rgba(52, 211, 153, 0.15);
      border: 1px solid rgba(52, 211, 153, 0.40);
      color: #00ff88;
    }
    .status-badge.offline {
      background: rgba(239, 68, 68, 0.15);
      border: 1px solid rgba(239, 68, 68, 0.40);
      color: #ff4444;
    }
    .status-badge.pending {
      background: rgba(255, 152, 0, 0.15);
      border: 1px solid rgba(255, 152, 0, 0.40);
      color: #ff9800;
    }
    
    /* Offline Banner */
    .offline-banner {
      background: #1f0a0a;
      border: 1px solid #ff4444;
      border-radius: 6px;
      color: #ff8888;
      padding: 1rem 1.2rem;
      margin: 1rem 0;
      font-size: 0.88rem;
      line-height: 1.7;
    }
    .offline-banner ul {
      margin: 0.5rem 0 0 1.2rem;
      padding: 0;
    }
    .offline-banner li {
      margin: 0.2rem 0;
    }
    .offline-banner code {
      background: rgba(0, 0, 0, 0.3);
      padding: 0.1rem 0.3rem;
      border-radius: 3px;
      font-family: monospace;
      font-size: 0.85em;
    }
    .offline-banner strong {
      color: #ffaaaa;
    }
    
    /* Section visibility */
    .hidden {
      display: none;
    }
    
    /* File info */
    .file-info {
      margin-top: .8rem;
      padding: .6rem;
      background: #111;
      border-radius: 6px;
      font-size: .85rem;
      color: #aaa;
    }
    
    /* Progress steps */
    .progress-steps {
      margin-top: .5rem;
      font-size: .8rem;
      color: #4fc3f7;
      font-family: monospace;
    }
  </style>
</head>

<body>
  <header class="nav">
    <div class="inner">
      <div class="brand">
        <img src="/logo.svg" alt="Neuromorphic Inference Lab" />
        <span>Neuromorphic Inference Lab</span>
      </div>
      <nav class="navlinks" aria-label="Primary navigation">
        <a data-nav href="/">Home</a>
        <a data-nav class="active" href="/demos/">Projects</a>
        <a data-nav href="/about/">About Me</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <!-- Section 1: Hero -->
    <section class="hero">
      <p class="kicker">PDF Knowledge Demo</p>
      <h1 class="h1">RAG Copilot â€” Document Q&A with Citations</h1>
      <p class="sub">
        Upload a PDF document (max 5000 words), build a vector index, and interact with contextual chat over your document with full citation tracing.
        Run automated benchmarks to evaluate retrieval precision, answer relevance, and context coverage.
      </p>
      <div class="badges">
        <span class="badge">RAG</span>
        <span class="badge">FAISS</span>
        <span class="badge">Citations</span>
        <span class="badge">Evaluation</span>
        <span id="systemStatus" class="status-badge offline">System Offline</span>
      </div>
    </section>

    <!-- Offline Banner (initially hidden) -->
    <div id="offlineBanner" class="offline-banner" style="display:none"></div>

    <!-- Section 2: Upload & Ingest -->
    <section class="section card">
      <h2>1. Upload & Index PDF</h2>
      <p class="sub">Select a PDF file (max 5000 words). The system will extract text, chunk it with sliding windows, and build a FAISS vector index.</p>
      
      <div id="uploadZone" class="upload-zone">
        <div style="font-size: 2rem; margin-bottom: .5rem;">ğŸ“„</div>
        <div style="font-weight: 600; margin-bottom: .3rem;">Drop PDF here or click to browse</div>
        <div style="font-size: .85rem; color: #888;">Maximum 5000 words</div>
        <input type="file" id="fileInput" accept=".pdf" style="display: none;" />
      </div>
      
      <div id="fileInfo" class="file-info hidden"></div>
      
      <div style="margin-top: 1rem;">
        <button id="ingestBtn" class="btn primary" disabled>â–¶ Start indexing</button>
      </div>
      
      <div id="progressContainer" class="hidden" style="margin-top: 1rem;">
        <div class="progress-bar-wrapper">
          <div id="progressBar" class="progress-bar"></div>
        </div>
        <div id="progressSteps" class="progress-steps"></div>
      </div>
      
      <div id="ingestResult" class="ingest-result hidden"></div>
    </section>

    <!-- Section 3: Chat -->
    <section id="chatSection" class="section card hidden">
      <h2>2. Chat with Your Document</h2>
      <p class="sub">Ask questions about your document. The system retrieves relevant chunks and generates contextual answers with citations.</p>
      
      <div id="chatWindow" class="chat-window"></div>
      
      <div class="chat-input-row">
        <input type="text" id="chatInput" placeholder="Ask a question about your document..." />
        <button id="sendBtn" class="btn primary">Send</button>
      </div>
    </section>

    <!-- Section 4: Benchmark -->
    <section id="benchmarkSection" class="section card hidden">
      <h2>3. Run Automated Benchmark</h2>
      <p class="sub">Generate synthetic test questions and evaluate the RAG pipeline with three reference-free metrics.</p>
      
      <div style="margin-top: 1rem;">
        <button id="benchmarkBtn" class="btn primary">âš¡ Run benchmark</button>
      </div>
      
      <div id="benchmarkResults" class="hidden" style="margin-top: 1.5rem;">
        <canvas id="metricsChart" width="600" height="300"></canvas>
        
        <table class="metrics-table">
          <thead>
            <tr>
              <th>Metric</th>
              <th>Score</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody id="metricsTableBody"></tbody>
        </table>
        
        <details style="margin-top: 1.5rem; padding: 1rem; background: #111; border-radius: 6px;">
          <summary style="cursor: pointer; font-weight: 600; margin-bottom: .5rem;">View Test Questions & Answers</summary>
          <div id="testQuestionsContainer" style="margin-top: 1rem;"></div>
        </details>
      </div>
    </section>

    <!-- Section 5: Project Overview -->
    <section class="section card">
      <h2>4. What This Project Does</h2>
      
      <p style="color: var(--muted); line-height: 1.7; margin-bottom: 1rem;">
        This is a Retrieval-Augmented Generation (RAG) system that lets you upload a PDF document and ask questions about it in natural language. Instead of searching for keywords, it understands the meaning of your question and finds relevant sections of your document to answer it.
      </p>
      
      <p style="color: var(--muted); line-height: 1.7; margin-bottom: 1rem;">
        The system solves the problem of extracting information from long documents. Rather than reading an entire PDF to find an answer, you can ask specific questions and get precise responses with references to the exact sections where the information came from.
      </p>
      
      <p style="color: var(--muted); line-height: 1.7; margin-bottom: 1rem;">
        This project demonstrates three capabilities: semantic search (finding relevant information based on meaning, not just keywords), question answering (generating accurate responses from document content), and automated evaluation (measuring how well the system performs without manual review).
      </p>
      
      <p style="color: var(--muted); line-height: 1.7; margin-bottom: 1rem;">
        The system includes guardrails to ensure answers come only from the uploaded document, provides citations so you can verify every answer, and includes an automated benchmark suite to measure retrieval quality, answer relevance, and index coverage.
      </p>
    </section>

    <!-- Section 6: Technical Deep-Dive -->
    <section class="section card">
      <h2>5. Technical Deep-Dive</h2>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Purpose and Scope</h3>
      <p style="color: var(--muted); line-height: 1.6;">
        This system implements a production-grade RAG pipeline for single-document question answering with citation tracing and automated evaluation. The scope is constrained to PDF documents under 5000 words, single-user sessions, and in-memory storage to keep the demo lightweight and deployable on free-tier infrastructure.
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Architecture and Design Decisions</h3>
      <p style="color: var(--muted); line-height: 1.6;">
        The architecture separates concerns into three distinct pipelines: ingest (document processing and indexing), retrieval (semantic search and answer generation), and evaluation (automated quality metrics). This design enables independent testing and optimization of each component. The system uses a stateless REST API with session-based storage, allowing horizontal scaling while maintaining simplicity.
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Data Flow and Execution Model</h3>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Ingest Pipeline</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        PDF â†’ Text extraction (pdfplumber) â†’ Word count validation (5000 limit) â†’ Sliding-window chunking (200 words per chunk, 40-word overlap to preserve context across boundaries) â†’ Sentence embedding (sentence-transformers with all-MiniLM-L6-v2 model) â†’ FAISS IndexFlatIP (cosine similarity on L2-normalized embeddings) â†’ In-memory session store.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">RAG Pipeline</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        User query â†’ Sentence embedding â†’ FAISS similarity search (top-4 chunks) â†’ Context injection into GPT-4o Mini prompt â†’ System prompt enforces answer-from-context-only constraint â†’ Response with citations (chunk IDs, text snippets, cosine scores, retrieval latency).
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Evaluation Pipeline</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Generate synthetic test questions (extract first sentence from random chunks) â†’ Run RAG pipeline on each question â†’ Compute three reference-free metrics: retrieval precision (average top-1 cosine score), answer relevance (cosine similarity between question and answer embeddings), context coverage (fraction of unique chunks retrieved across all queries).
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Implementation Details</h3>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Chunking Strategy</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Sliding-window chunking with 200-word chunks and 40-word overlap ensures that semantic units (paragraphs, concepts) are not split across chunk boundaries, improving retrieval quality. Fixed-size chunks simplify embedding and enable consistent retrieval latency.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Embedding Model Selection</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        all-MiniLM-L6-v2 balances quality and speed (384-dimensional embeddings, 14M parameters, ~120ms inference on 2-core CPU). Chosen for acceptable semantic similarity performance without requiring GPU infrastructure. Production systems would use larger models (e.g., text-embedding-3-large) or domain-specific fine-tuned models.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Vector Index Design</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        FAISS IndexFlatIP provides exact nearest-neighbor search with cosine similarity (via L2-normalized embeddings and inner product). No approximate search (ANN) is needed for small document collections (&lt;100 chunks). Production systems with larger corpora would use HNSW or IVF indexes for sub-linear search complexity.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">LLM Selection and Prompt Engineering</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        GPT-4o Mini was chosen for cost efficiency ($0.15 per 1M input tokens vs $2.50 for GPT-4o) while maintaining acceptable answer quality. The system prompt explicitly constrains the model to answer only from provided context and refuse out-of-scope questions. This reduces hallucination risk but requires good retrieval quality to avoid "I don't know" responses.
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Full Technology Stack</h3>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Backend</h4>
      <ul style="color: var(--muted); line-height: 1.8; padding-left: 1.5rem;">
        <li><strong>Python 3.11:</strong> Language runtime (async support, type hints, performance)</li>
        <li><strong>FastAPI 0.104:</strong> Web framework (automatic OpenAPI docs, async, validation with Pydantic)</li>
        <li><strong>pdfplumber 0.10:</strong> PDF text extraction (preserves layout, handles complex PDFs)</li>
        <li><strong>sentence-transformers 2.2:</strong> Embedding generation (wraps HuggingFace models)</li>
        <li><strong>FAISS 1.7:</strong> Vector similarity search (Facebook AI Similarity Search library)</li>
        <li><strong>OpenAI Python SDK 1.3:</strong> GPT-4o Mini API client</li>
        <li><strong>Uvicorn 0.24:</strong> ASGI server (production-ready, async, HTTP/2)</li>
        <li><strong>python-multipart 0.0.6:</strong> Multipart form data parsing (file uploads)</li>
      </ul>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Infrastructure</h4>
      <ul style="color: var(--muted); line-height: 1.8; padding-left: 1.5rem;">
        <li><strong>Docker:</strong> Containerization for reproducible builds and deployment</li>
        <li><strong>Render:</strong> Backend hosting (free tier, auto-scaling, zero-config HTTPS, environment variables for secrets)</li>
        <li><strong>Cloudflare Pages:</strong> Frontend hosting (global CDN, instant deploys, automatic HTTPS)</li>
      </ul>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Frontend</h4>
      <ul style="color: var(--muted); line-height: 1.8; padding-left: 1.5rem;">
        <li><strong>Vanilla JavaScript:</strong> No framework dependencies (faster load, easier debugging, no build step)</li>
        <li><strong>HTML5 + CSS3:</strong> Native file upload API, Fetch API for HTTP, Canvas API for charts</li>
      </ul>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">MLOps/LLMOps</h4>
      <ul style="color: var(--muted); line-height: 1.8; padding-left: 1.5rem;">
        <li><strong>Reference-free evaluation metrics:</strong> No human labeling required for quality assessment</li>
        <li><strong>Session-based state management:</strong> Isolated user sessions, no shared state pollution</li>
        <li><strong>Citation tracing:</strong> Every answer includes provenance (chunk IDs, scores, latency)</li>
        <li><strong>Environment-based configuration:</strong> API keys injected via environment variables, never committed to source control</li>
      </ul>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Technical Challenges and Trade-offs</h3>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Challenge: Chunking Strategy</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        <strong>Problem:</strong> Fixed-size chunks can split semantic units mid-sentence, degrading retrieval quality.<br>
        <strong>Solution:</strong> Sliding-window chunking with 40-word overlap preserves context across boundaries. Trade-off: 20% storage overhead (overlapping words stored multiple times) for better retrieval quality.<br>
        <strong>Alternative considered:</strong> Semantic chunking (split on paragraph boundaries) â€” rejected due to variable chunk sizes complicating embedding batching and retrieval normalization.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Challenge: Evaluation Without Ground Truth</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        <strong>Problem:</strong> Manual labeling of question-answer pairs is expensive and not scalable.<br>
        <strong>Solution:</strong> Reference-free metrics (retrieval precision, answer relevance, context coverage) provide proxy signals for system health without human annotation. Trade-off: Metrics don't capture factual correctness, only correlation and coverage.<br>
        <strong>Alternative considered:</strong> LLM-as-judge evaluation (GPT-4 evaluates answer quality) â€” rejected due to cost ($2.50 per 1M tokens) and latency (adds 2-5s per evaluation).
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Challenge: Cold Start on Free-Tier Hosting</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        <strong>Problem:</strong> Render free tier spins down services after 15 minutes of inactivity, causing 30-60s cold starts.<br>
        <strong>Solution:</strong> Health check with retry logic (3 attempts, 3s delay) and user-facing status indicator. Trade-off: Degraded UX on first request, but acceptable for demo purposes.<br>
        <strong>Alternative considered:</strong> Keep-alive pings to prevent spin-down â€” rejected to stay within free-tier limits and avoid unnecessary API usage.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Challenge: In-Memory Storage Constraints</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        <strong>Problem:</strong> FAISS index and document chunks stored in memory, limiting concurrent users and document sizes.<br>
        <strong>Solution:</strong> Session-based storage with 5000-word document limit. Trade-off: No persistence across restarts, single-user sessions only. Production systems would use vector databases (Pinecone, Weaviate, Qdrant) with persistent storage.<br>
        <strong>Alternative considered:</strong> SQLite + FAISS serialization â€” rejected due to deployment complexity and filesystem write permissions on Render free tier.
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Technology Selection Rationale</h3>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Why FastAPI?</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Automatic OpenAPI documentation (critical for API debugging), native async support (required for OpenAI API calls), and Pydantic validation (type-safe request/response models). Alternative (Flask) lacks async and automatic docs. Alternative (Django) is overkill for stateless API.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Why FAISS?</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Industry-standard vector search library with battle-tested performance. Supports exact and approximate search algorithms. Alternatives (Annoy, ScaNN) have narrower feature sets or less Python support. Vector databases (Pinecone, Weaviate) are overkill for in-memory demo use case.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Why GPT-4o Mini?</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Cost efficiency ($0.15 per 1M input tokens) with acceptable answer quality. GPT-4o ($2.50 per 1M tokens) provides marginal quality improvement at 16x cost. Open-source alternatives (Llama 3, Mistral) require GPU infrastructure and self-hosting complexity.
      </p>
      
      <h4 style="margin-top: 1rem; font-size: 1rem; color: #00ff88;">Why Vanilla JavaScript?</h4>
      <p style="color: var(--muted); line-height: 1.6;">
        Zero build step (instant deploys), faster page load (no framework bundle), easier debugging (no transpilation). React/Vue would add complexity without meaningful UX benefit for this interactive demo.
      </p>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Demo Limitations</h3>
      <ul style="color: var(--muted); line-height: 1.8; padding-left: 1.5rem;">
        <li><strong>No persistence:</strong> Index and chunks stored in-memory, lost on server restart</li>
        <li><strong>5000-word limit:</strong> Prevents memory exhaustion on free-tier infrastructure</li>
        <li><strong>Single-user sessions:</strong> No authentication or multi-tenancy support</li>
        <li><strong>Reference-free metrics:</strong> Evaluation proxies don't measure factual correctness</li>
        <li><strong>Cold start latency:</strong> 30-60s delay on first request after 15-minute idle period</li>
        <li><strong>No production monitoring:</strong> No structured logging, error tracking, or observability</li>
      </ul>
      
      <h3 style="margin-top: 1.5rem; font-size: 1.1rem; color: #4fc3f7;">Architecture Diagram</h3>
      <div class="architecture-diagram">
        <pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT (Browser)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ PDF Upload   â”‚  â”‚ Chat UI      â”‚  â”‚ Benchmark UI â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â”‚ POST /ingest     â”‚ POST /chat       â”‚ POST /eval
          â”‚ (multipart/form) â”‚ (JSON)           â”‚ (JSON)
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI BACKEND (Render)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Routers: /api/v1/ingest, /api/v1/chat, /api/v1/eval      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                  â”‚             â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PDF Parser       â”‚  â”‚ Retriever       â”‚  â”‚ Evaluator      â”‚  â”‚
â”‚  â”‚ (pdfplumber)     â”‚  â”‚ (FAISS search)  â”‚  â”‚ (metrics calc) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                      â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Chunker          â”‚  â”‚ GPT-4o Mini      â”‚                     â”‚
â”‚  â”‚ (sliding window) â”‚  â”‚ (OpenAI API)     â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚           â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ Embedder (sentence-transformers) â”‚                           â”‚
â”‚  â”‚ Model: all-MiniLM-L6-v2          â”‚                           â”‚
â”‚  â”‚ FAISS IndexFlatIP (cosine sim)   â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ Session Store (in-memory)        â”‚                           â”‚
â”‚  â”‚ {session_id: {index, chunks, â€¦}} â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        </pre>
      </div>
    </section>

    <footer class="footer">
      <div>Â© <span id="year"></span> Neuromorphic Inference Lab</div>
      <div class="prov">
        <span id="build-branch">branch: â€¦</span>
        <span id="build-commit">commit: â€¦</span>
        <span id="build-time">built: â€¦</span>
      </div>
    </footer>
  </main>

  <script>
    // Configuration
    // Auto-detect environment: use localhost if running locally, otherwise use production
    const isLocal = window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1';
    const PROD_API_BASE = "https://nil-rag-copilot.onrender.com/api/v1";
    const PROD_API_ROOT = "https://nil-rag-copilot.onrender.com";
    const LOCAL_API_BASE = "http://localhost:8080/api/v1";
    const LOCAL_API_ROOT = "http://localhost:8080";
    
    // Use local backend if running locally, otherwise use production
    const API_BASE = isLocal ? LOCAL_API_BASE : PROD_API_BASE;
    const API_ROOT = isLocal ? LOCAL_API_ROOT : PROD_API_ROOT;
    
    console.log(`Environment: ${isLocal ? 'LOCAL' : 'PRODUCTION'}`);
    console.log(`API_BASE: ${API_BASE}`);
    
    // State
    let sessionId = null;
    let selectedFile = null;
    
    // DOM Elements
    const uploadZone = document.getElementById('uploadZone');
    const fileInput = document.getElementById('fileInput');
    const fileInfo = document.getElementById('fileInfo');
    const ingestBtn = document.getElementById('ingestBtn');
    const progressContainer = document.getElementById('progressContainer');
    const progressBar = document.getElementById('progressBar');
    const progressSteps = document.getElementById('progressSteps');
    const ingestResult = document.getElementById('ingestResult');
    const chatSection = document.getElementById('chatSection');
    const chatWindow = document.getElementById('chatWindow');
    const chatInput = document.getElementById('chatInput');
    const sendBtn = document.getElementById('sendBtn');
    const benchmarkSection = document.getElementById('benchmarkSection');
    const benchmarkBtn = document.getElementById('benchmarkBtn');
    const benchmarkResults = document.getElementById('benchmarkResults');
    const systemStatus = document.getElementById('systemStatus');
    
    // Initialize
    document.getElementById('year').textContent = String(new Date().getFullYear());
    
    // System health check with retry logic
    const HEALTH_URL = API_ROOT + "/health";

    async function checkBackendHealth() {
      const badge = document.getElementById("systemStatus");
      badge.textContent = "â³ Connectingâ€¦";
      badge.className = "status-badge pending";

      for (let attempt = 1; attempt <= 3; attempt++) {
        try {
          const res = await fetch(HEALTH_URL, {
            method: "GET",
            signal: AbortSignal.timeout(8000),
          });
          if (res.ok) {
            badge.textContent = "â— System online";
            badge.className = "status-badge online";
            return true;
          }
        } catch (err) {
          console.error(`Health check attempt ${attempt} failed:`, err);
          if (attempt < 3) {
            badge.textContent = `â³ Retryingâ€¦ (${attempt}/3)`;
            await new Promise(r => setTimeout(r, 3000));
          }
        }
      }

      badge.textContent = "âš  System Offline";
      badge.className = "status-badge offline";

      const banner = document.getElementById("offlineBanner");
      if (banner) {
        banner.style.display = "block";
        banner.innerHTML = `
          <strong>âš  Backend not reachable</strong><br>
          The API at <code>${HEALTH_URL}</code> did not respond.<br>
          <strong>Likely causes:</strong>
          <ul>
            <li>Backend not deployed yet â€” push to GitHub and deploy on Render.</li>
            <li>Render free tier is cold-starting (wait 30â€“60 s, then refresh).</li>
            <li><code>API_BASE</code> in the HTML points to a wrong URL.</li>
            <li>CORS not configured for this origin on the backend.</li>
          </ul>
        `;
      }
      return false;
    }

    // Run health check on page load
    document.addEventListener("DOMContentLoaded", async () => {
      const isOnline = await checkBackendHealth();
      if (!isOnline) {
        const btn = document.getElementById("ingestBtn");
        if (btn) {
          btn.disabled = true;
          btn.title = "Backend offline â€” deploy the API first";
        }
      }
    });
    
    // File upload handlers
    uploadZone.addEventListener('click', () => fileInput.click());
    
    uploadZone.addEventListener('dragover', (e) => {
      e.preventDefault();
      uploadZone.classList.add('drag-over');
    });
    
    uploadZone.addEventListener('dragleave', () => {
      uploadZone.classList.remove('drag-over');
    });
    
    uploadZone.addEventListener('drop', (e) => {
      e.preventDefault();
      uploadZone.classList.remove('drag-over');
      const files = e.dataTransfer.files;
      if (files.length > 0) {
        handleFileSelect(files[0]);
      }
    });
    
    fileInput.addEventListener('change', (e) => {
      if (e.target.files.length > 0) {
        handleFileSelect(e.target.files[0]);
      }
    });
    
    function handleFileSelect(file) {
      // Validate PDF
      if (file.type !== 'application/pdf') {
        showIngestResult('error', 'âœ— Please select a PDF file.');
        return;
      }
      
      selectedFile = file;
      const sizeKB = (file.size / 1024).toFixed(2);
      fileInfo.innerHTML = `<strong>${file.name}</strong> (${sizeKB} KB)`;
      fileInfo.classList.remove('hidden');
      ingestBtn.disabled = false;
    }
    
    // Ingest handler
    ingestBtn.addEventListener('click', async () => {
      if (!selectedFile) return;
      
      ingestBtn.disabled = true;
      ingestResult.classList.add('hidden');
      progressContainer.classList.remove('hidden');
      
      // Simulate progress steps (visual feedback only - actual progress depends on server processing time)
      updateProgress(30, 'Extracting textâ€¦');
      
      const formData = new FormData();
      formData.append('file', selectedFile);
      
      try {
        setTimeout(() => updateProgress(60, 'Building vector indexâ€¦'), 500);
        
        const response = await fetch(`${API_BASE}/ingest`, {
          method: 'POST',
          body: formData,
          mode: 'cors'
        });
        
        const data = await response.json();
        
        if (response.ok) {
          updateProgress(100, 'Done');
          sessionId = data.session_id;
          
          setTimeout(() => {
            progressContainer.classList.add('hidden');
            showIngestResult('success', 
              `âœ“ ${data.message}<br>` +
              `Session ID: ${data.session_id}<br>` +
              `Words: ${data.word_count} | Chunks: ${data.chunk_count}`
            );
            
            // Show chat and benchmark sections
            chatSection.classList.remove('hidden');
            benchmarkSection.classList.remove('hidden');
            addSystemMessage('Index ready. You can now ask questions about your document.');
          }, 500);
        } else {
          progressContainer.classList.add('hidden');
          const errorDetail = escapeHtml(data.error || data.detail || 'Unknown error');
          let errorMsg = `âœ— Error ${response.status}: ${errorDetail}`;
          if (response.status === 404) {
            // API_BASE is our own constant, no need to escape
            errorMsg += '<br><small>Backend route not found. Please verify:<br>' +
                        '1. Backend service is deployed and running<br>' +
                        '2. API_BASE URL in code matches deployed service<br>' +
                        `3. Expected route: ${API_BASE}/ingest</small>`;
          }
          showIngestResult('error', errorMsg);
          ingestBtn.disabled = false;
        }
      } catch (err) {
        progressContainer.classList.add('hidden');
        const escapedErrMsg = escapeHtml(err.message);
        let errorMsg = `âœ— Network error: ${escapedErrMsg}`;
        if (err.message.includes('Failed to fetch')) {
          errorMsg += '<br><small>Cannot reach backend. Check if service is running and CORS is configured.</small>';
        }
        showIngestResult('error', errorMsg);
        ingestBtn.disabled = false;
      }
    });
    
    // Helper to safely escape HTML in dynamic content (e.g., error messages from backend)
    function escapeHtml(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }
    
    function updateProgress(percent, step) {
      progressBar.style.width = `${percent}%`;
      progressSteps.textContent = step;
    }
    
    function showIngestResult(type, message) {
      ingestResult.className = `ingest-result ${type}`;
      // Security model: Message contains pre-escaped dynamic content (error messages from
      // backend/JS) mixed with intentional HTML tags (<br>, <small>) for formatting.
      // Only untrusted data (backend errors, JS error messages) is escaped via escapeHtml().
      // Trusted HTML structure is controlled by our code and safe to render.
      // Note: This approach is acceptable for this use case but requires careful attention
      // when adding new error messages. Consider using DOM methods or a template library
      // for more complex scenarios.
      ingestResult.innerHTML = message;
      ingestResult.classList.remove('hidden');
    }
    
    // Chat handlers
    sendBtn.addEventListener('click', sendMessage);
    chatInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter') sendMessage();
    });
    
    async function sendMessage() {
      const question = chatInput.value.trim();
      if (!question || !sessionId) return;
      
      // Add user message
      addMessage('user', question);
      chatInput.value = '';
      sendBtn.disabled = true;
      
      try {
        const response = await fetch(`${API_BASE}/chat`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId, question }),
          mode: 'cors'
        });
        
        const data = await response.json();
        
        if (response.ok) {
          addAssistantMessage(data.answer, data.citations, data.retrieval_latency_ms);
        } else {
          addMessage('error', `Error: ${data.error || data.detail || 'Unknown error'}`);
        }
      } catch (err) {
        addMessage('error', `Network error: ${err.message}`);
      } finally {
        sendBtn.disabled = false;
      }
    }
    
    function addMessage(type, text) {
      const msg = document.createElement('div');
      msg.className = `chat-message ${type}`;
      msg.textContent = text;
      chatWindow.appendChild(msg);
      chatWindow.scrollTop = chatWindow.scrollHeight;
    }
    
    function addSystemMessage(text) {
      addMessage('system', text);
    }
    
    function addAssistantMessage(answer, citations, latency) {
      const msg = document.createElement('div');
      msg.className = 'chat-message assistant';
      
      const answerDiv = document.createElement('div');
      answerDiv.textContent = answer;
      msg.appendChild(answerDiv);
      
      if (citations && citations.length > 0) {
        const citationsDiv = document.createElement('div');
        citationsDiv.className = 'citations-block';
        
        const toggle = document.createElement('div');
        toggle.className = 'citation-toggle';
        toggle.textContent = `â–¸ Show ${citations.length} citation(s) | Latency: ${latency}ms`;
        
        const citationsList = document.createElement('div');
        citationsList.style.display = 'none';
        citationsList.style.marginTop = '.5rem';
        
        citations.forEach(cit => {
          const citDiv = document.createElement('div');
          citDiv.className = 'citation';
          citDiv.innerHTML = 
            `<strong>Chunk ${cit.chunk_id}</strong> (score: ${cit.score.toFixed(3)})<br>` +
            `<em>${cit.text_snippet}</em>`;
          citationsList.appendChild(citDiv);
        });
        
        toggle.addEventListener('click', () => {
          const isHidden = citationsList.style.display === 'none';
          citationsList.style.display = isHidden ? 'block' : 'none';
          toggle.textContent = `${isHidden ? 'â–¾' : 'â–¸'} ${isHidden ? 'Hide' : 'Show'} ${citations.length} citation(s) | Latency: ${latency}ms`;
        });
        
        citationsDiv.appendChild(toggle);
        citationsDiv.appendChild(citationsList);
        msg.appendChild(citationsDiv);
      }
      
      chatWindow.appendChild(msg);
      chatWindow.scrollTop = chatWindow.scrollHeight;
    }
    
    // Benchmark handler
    benchmarkBtn.addEventListener('click', async () => {
      if (!sessionId) return;
      
      benchmarkBtn.disabled = true;
      benchmarkBtn.innerHTML = '<span class="spinner"></span>Running benchmark...';
      
      try {
        const response = await fetch(`${API_BASE}/eval`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ session_id: sessionId }),
          mode: 'cors'
        });
        
        const data = await response.json();
        
        if (response.ok) {
          displayBenchmarkResults(data);
        } else {
          alert(`Error: ${data.error || data.detail || 'Unknown error'}`);
        }
      } catch (err) {
        alert(`Network error: ${err.message}`);
      } finally {
        benchmarkBtn.disabled = false;
        benchmarkBtn.innerHTML = 'âš¡ Run benchmark';
      }
    });
    
    function displayBenchmarkResults(data) {
      benchmarkResults.classList.remove('hidden');
      
      // Render chart
      renderMetricsChart(data.metrics);
      
      // Populate table
      const tbody = document.getElementById('metricsTableBody');
      tbody.innerHTML = '';
      data.metrics.forEach(m => {
        const row = tbody.insertRow();
        row.insertCell(0).textContent = m.name;
        const scoreCell = row.insertCell(1);
        scoreCell.className = 'score-cell';
        scoreCell.textContent = m.score.toFixed(3);
        row.insertCell(2).textContent = m.description;
      });
      
      // Show test Q&A
      const qaContainer = document.getElementById('testQuestionsContainer');
      qaContainer.innerHTML = '';
      data.test_questions.forEach((q, i) => {
        const qaDiv = document.createElement('div');
        qaDiv.style.marginBottom = '1rem';
        qaDiv.style.padding = '.8rem';
        qaDiv.style.background = '#0a0a0a';
        qaDiv.style.borderRadius = '6px';
        qaDiv.innerHTML = 
          `<strong style="color: #4fc3f7;">Q${i+1}:</strong> ${q}<br>` +
          `<strong style="color: #00ff88;">A:</strong> ${data.answers[i]}`;
        qaContainer.appendChild(qaDiv);
      });
    }
    
    function renderMetricsChart(metrics) {
      const canvas = document.getElementById('metricsChart');
      const ctx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      
      // Clear canvas
      ctx.fillStyle = '#0d0d0d';
      ctx.fillRect(0, 0, width, height);
      
      // Chart settings
      const padding = 50;
      const barWidth = 80;
      const maxValue = 1.0;
      const chartHeight = height - padding * 2;
      const chartWidth = width - padding * 2;
      const barSpacing = (chartWidth - (barWidth * metrics.length)) / (metrics.length + 1);
      
      // Colors
      const colors = ['#00ff88', '#4fc3f7', '#ff9800'];
      const GRADIENT_ALPHA = '66'; // 40% opacity (0x66 = 102/255 â‰ˆ 0.4)
      
      // Draw Y-axis
      ctx.strokeStyle = '#333';
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(padding, padding);
      ctx.lineTo(padding, height - padding);
      ctx.stroke();
      
      // Draw Y-axis labels
      ctx.fillStyle = '#888';
      ctx.font = '12px monospace';
      ctx.textAlign = 'right';
      for (let i = 0; i <= 5; i++) {
        const y = padding + (chartHeight * i / 5);
        const value = (1 - i / 5).toFixed(1);
        ctx.fillText(value, padding - 10, y + 4);
        
        // Grid lines
        ctx.strokeStyle = '#1a1a1a';
        ctx.beginPath();
        ctx.moveTo(padding, y);
        ctx.lineTo(width - padding, y);
        ctx.stroke();
      }
      
      // Draw bars
      metrics.forEach((metric, i) => {
        const x = padding + barSpacing + i * (barWidth + barSpacing);
        const barHeight = (metric.score / maxValue) * chartHeight;
        const y = height - padding - barHeight;
        
        // Gradient fill
        const gradient = ctx.createLinearGradient(x, y, x, height - padding);
        gradient.addColorStop(0, colors[i]);
        gradient.addColorStop(1, colors[i] + GRADIENT_ALPHA);
        ctx.fillStyle = gradient;
        ctx.fillRect(x, y, barWidth, barHeight);
        
        // Border
        ctx.strokeStyle = colors[i];
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, barWidth, barHeight);
        
        // Value label
        ctx.fillStyle = colors[i];
        ctx.font = 'bold 14px monospace';
        ctx.textAlign = 'center';
        ctx.fillText(metric.score.toFixed(3), x + barWidth / 2, y - 10);
        
        // Metric name
        ctx.fillStyle = '#ccc';
        ctx.font = '11px monospace';
        const words = metric.name.split(' ');
        words.forEach((word, wi) => {
          ctx.fillText(word, x + barWidth / 2, height - padding + 20 + wi * 14);
        });
      });
    }
  </script>
  
  <script src="/build-info.js"></script>
</body>
</html>
